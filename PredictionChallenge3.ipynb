{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chandhinipj/CartPole-V0-ReinforcementLearning/blob/main/PredictionChallenge3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VKK5DA390wRe"
      },
      "source": [
        "# Skeleton Code for Prediction Challenge 3\n",
        "Below is partial code to get you started on prediction challenge 3. You need to select values for the parameters that have question marks."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install keras-rl2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DNGTghHEhyW4",
        "outputId": "f22de868-9dbf-4f47-f904-b170c64fff71"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: keras-rl2 in /usr/local/lib/python3.9/dist-packages (1.0.5)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.9/dist-packages (from keras-rl2) (2.11.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow->keras-rl2) (3.8.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.9/dist-packages (from tensorflow->keras-rl2) (67.6.0)\n",
            "Requirement already satisfied: keras<2.12,>=2.11.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow->keras-rl2) (2.11.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.9/dist-packages (from tensorflow->keras-rl2) (3.3.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.9/dist-packages (from tensorflow->keras-rl2) (0.2.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow->keras-rl2) (1.4.0)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.9/dist-packages (from tensorflow->keras-rl2) (0.4.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow->keras-rl2) (2.2.0)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.9/dist-packages (from tensorflow->keras-rl2) (3.19.6)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.9/dist-packages (from tensorflow->keras-rl2) (1.22.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.9/dist-packages (from tensorflow->keras-rl2) (23.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.9/dist-packages (from tensorflow->keras-rl2) (1.51.3)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.9/dist-packages (from tensorflow->keras-rl2) (4.5.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow->keras-rl2) (1.16.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.12,>=2.11.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow->keras-rl2) (2.11.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow->keras-rl2) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow->keras-rl2) (23.3.3)\n",
            "Requirement already satisfied: tensorboard<2.12,>=2.11 in /usr/local/lib/python3.9/dist-packages (from tensorflow->keras-rl2) (2.11.2)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow->keras-rl2) (15.0.6.1)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow->keras-rl2) (1.15.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.9/dist-packages (from tensorflow->keras-rl2) (0.31.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.9/dist-packages (from astunparse>=1.6.0->tensorflow->keras-rl2) (0.40.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.12,>=2.11->tensorflow->keras-rl2) (0.4.6)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.12,>=2.11->tensorflow->keras-rl2) (2.2.3)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.12,>=2.11->tensorflow->keras-rl2) (0.6.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.12,>=2.11->tensorflow->keras-rl2) (3.4.3)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.12,>=2.11->tensorflow->keras-rl2) (2.16.2)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.12,>=2.11->tensorflow->keras-rl2) (2.27.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.12,>=2.11->tensorflow->keras-rl2) (1.8.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow->keras-rl2) (5.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow->keras-rl2) (4.9)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow->keras-rl2) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.9/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow->keras-rl2) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.9/dist-packages (from markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow->keras-rl2) (6.1.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow->keras-rl2) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow->keras-rl2) (1.26.15)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow->keras-rl2) (3.4)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow->keras-rl2) (2.0.12)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.9/dist-packages (from werkzeug>=1.0.1->tensorboard<2.12,>=2.11->tensorflow->keras-rl2) (2.1.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.9/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow->keras-rl2) (3.15.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.9/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow->keras-rl2) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.9/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow->keras-rl2) (3.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gym"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eQ_dXOCKh0jV",
        "outputId": "0ad8ee08-5c46-4fb0-dcf5-9c9ad431888d"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: gym in /usr/local/lib/python3.9/dist-packages (0.25.2)\n",
            "Requirement already satisfied: importlib-metadata>=4.8.0 in /usr/local/lib/python3.9/dist-packages (from gym) (6.1.0)\n",
            "Requirement already satisfied: gym-notices>=0.0.4 in /usr/local/lib/python3.9/dist-packages (from gym) (0.0.8)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.9/dist-packages (from gym) (2.2.1)\n",
            "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.9/dist-packages (from gym) (1.22.4)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.9/dist-packages (from importlib-metadata>=4.8.0->gym) (3.15.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# load the gym module\n",
        "import gym\n",
        "import matplotlib.pyplot as plt\n",
        "# import the usual Keras modules for creating deep neural networks\n",
        "from keras import Sequential\n",
        "from keras.layers import Input, Flatten, Dense\n",
        "from keras.optimizers import Adam\n",
        "\n",
        "ENV_NAME = 'CartPole-v0'\n",
        "env = gym.make(ENV_NAME)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "75Phf54nh2y_",
        "outputId": "31b7b33d-8433-4c31-eb25-4924c3515e7c"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/gym/envs/registration.py:593: UserWarning: \u001b[33mWARN: The environment CartPole-v0 is out of date. You should consider upgrading to version `v1`.\u001b[0m\n",
            "  logger.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/gym/core.py:317: DeprecationWarning: \u001b[33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
            "  deprecation(\n",
            "/usr/local/lib/python3.9/dist-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: \u001b[33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
            "  deprecation(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import rl\n",
        "from rl.memory import SequentialMemory  # import the exerience replay buffer module\n",
        "from rl.policy import LinearAnnealedPolicy, EpsGreedyQPolicy  # import the policy\n",
        "from rl.agents.dqn import DQNAgent      # import the DQN agent"
      ],
      "metadata": {
        "id": "KsGYDOrDh58e"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Q-Network\n",
        "model = Sequential()\n",
        "model.add(Input(shape=(1,env.observation_space.shape[0])))  # The input is 1 observation vector, and the number of observations in that vector \n",
        "model.add(Flatten())\n",
        "# add extra layers here\n",
        "model.add(Dense(16, activation='relu'))\n",
        "model.add(Dense(32, activation='relu'))\n",
        "# model.add(Dense(64, activation='relu'))\n",
        "# model.add(Dense(128, activation='relu'))\n",
        "\n",
        "model.add(Dense(env.action_space.n, activation='linear'))   # the output is the number of actions in the action space\n",
        "print(model.summary())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i5dvD8xTio0U",
        "outputId": "bf4089bd-cad0-4b8d-ddb4-d0ac113f8748"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten (Flatten)           (None, 4)                 0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 16)                80        \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 32)                544       \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 2)                 66        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 690\n",
            "Trainable params: 690\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R8ZiiRbxlH2D",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d2efc27c-65b6-4cab-8d5e-4906edfd09ff"
      },
      "source": [
        "memory = SequentialMemory(limit=5000, window_length=1)\n",
        "\n",
        "# define the policy\n",
        "policy =  LinearAnnealedPolicy(inner_policy=EpsGreedyQPolicy(eps=0.2), \n",
        "                               attr='eps',            \n",
        "                               value_max=1.0,\n",
        "                               value_min=0.1, \n",
        "                               value_test=.05,\n",
        "                               nb_steps=5000)\n",
        "\n",
        "\n",
        "# define the agent\n",
        "dqn = DQNAgent(model=model, \n",
        "               nb_actions=env.action_space.n,\n",
        "               memory=memory,\n",
        "               nb_steps_warmup=100,\n",
        "               target_model_update=1e-2, \n",
        "               policy=policy) \n",
        "\n",
        "dqn.compile(Adam(lr=1e-3), metrics=['mae'])\n",
        "\n",
        "history = dqn.fit(env, nb_steps=5000, visualize=False, verbose=2)\n",
        "\n",
        "# summarize the history for number  of episode steps\n",
        "plt.plot(history.history['nb_episode_steps'])\n",
        "plt.ylabel('nb_episode_steps')\n",
        "plt.xlabel('episodes')\n",
        "plt.show()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/keras/optimizers/optimizer_v2/adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super().__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training for 5000 steps ...\n",
            "   13/5000: episode: 1, duration: 0.108s, episode steps:  13, steps per second: 121, episode reward: 13.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.231 [0.000, 1.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "   32/5000: episode: 2, duration: 0.014s, episode steps:  19, steps per second: 1314, episode reward: 19.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.632 [0.000, 1.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "   62/5000: episode: 3, duration: 0.023s, episode steps:  30, steps per second: 1290, episode reward: 30.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.533 [0.000, 1.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "   75/5000: episode: 4, duration: 0.010s, episode steps:  13, steps per second: 1248, episode reward: 13.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.231 [0.000, 1.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/keras/engine/training_v1.py:2357: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
            "  updates=self.state_updates,\n",
            "/usr/local/lib/python3.9/dist-packages/keras/engine/training_v1.py:2357: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
            "  updates=self.state_updates,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  105/5000: episode: 5, duration: 0.677s, episode steps:  30, steps per second:  44, episode reward: 30.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.567 [0.000, 1.000],  loss: 4.679460, mae: 7.114057, mean_q: 12.681247, mean_eps: 0.981550\n",
            "  150/5000: episode: 6, duration: 0.312s, episode steps:  45, steps per second: 144, episode reward: 45.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.600 [0.000, 1.000],  loss: 2.325196, mae: 7.079136, mean_q: 13.504586, mean_eps: 0.977140\n",
            "  160/5000: episode: 7, duration: 0.069s, episode steps:  10, steps per second: 146, episode reward: 10.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.700 [0.000, 1.000],  loss: 3.250010, mae: 7.265631, mean_q: 13.841727, mean_eps: 0.972190\n",
            "  182/5000: episode: 8, duration: 0.151s, episode steps:  22, steps per second: 146, episode reward: 22.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 3.389078, mae: 7.240316, mean_q: 13.519675, mean_eps: 0.969310\n",
            "  206/5000: episode: 9, duration: 0.167s, episode steps:  24, steps per second: 144, episode reward: 24.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.458 [0.000, 1.000],  loss: 2.190196, mae: 7.245023, mean_q: 14.001202, mean_eps: 0.965170\n",
            "  230/5000: episode: 10, duration: 0.175s, episode steps:  24, steps per second: 137, episode reward: 24.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.625 [0.000, 1.000],  loss: 2.830356, mae: 7.368747, mean_q: 13.936608, mean_eps: 0.960850\n",
            "  256/5000: episode: 11, duration: 0.210s, episode steps:  26, steps per second: 124, episode reward: 26.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 3.553330, mae: 7.430789, mean_q: 13.911768, mean_eps: 0.956350\n",
            "  270/5000: episode: 12, duration: 0.145s, episode steps:  14, steps per second:  97, episode reward: 14.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.571 [0.000, 1.000],  loss: 2.573027, mae: 7.427400, mean_q: 14.243830, mean_eps: 0.952750\n",
            "  293/5000: episode: 13, duration: 0.251s, episode steps:  23, steps per second:  91, episode reward: 23.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.522 [0.000, 1.000],  loss: 3.614489, mae: 7.541879, mean_q: 14.154076, mean_eps: 0.949420\n",
            "  320/5000: episode: 14, duration: 0.286s, episode steps:  27, steps per second:  95, episode reward: 27.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.370 [0.000, 1.000],  loss: 2.268892, mae: 7.557771, mean_q: 14.531669, mean_eps: 0.944920\n",
            "  347/5000: episode: 15, duration: 0.265s, episode steps:  27, steps per second: 102, episode reward: 27.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.444 [0.000, 1.000],  loss: 4.028487, mae: 7.724977, mean_q: 14.345455, mean_eps: 0.940060\n",
            "  362/5000: episode: 16, duration: 0.154s, episode steps:  15, steps per second:  98, episode reward: 15.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.667 [0.000, 1.000],  loss: 2.434896, mae: 7.649692, mean_q: 14.528170, mean_eps: 0.936280\n",
            "  407/5000: episode: 17, duration: 0.445s, episode steps:  45, steps per second: 101, episode reward: 45.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.556 [0.000, 1.000],  loss: 3.170941, mae: 7.711133, mean_q: 14.595453, mean_eps: 0.930880\n",
            "  429/5000: episode: 18, duration: 0.221s, episode steps:  22, steps per second: 100, episode reward: 22.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.364 [0.000, 1.000],  loss: 3.963950, mae: 7.800093, mean_q: 14.462905, mean_eps: 0.924850\n",
            "  441/5000: episode: 19, duration: 0.121s, episode steps:  12, steps per second:  99, episode reward: 12.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.417 [0.000, 1.000],  loss: 2.846739, mae: 7.765050, mean_q: 14.616588, mean_eps: 0.921790\n",
            "  456/5000: episode: 20, duration: 0.156s, episode steps:  15, steps per second:  96, episode reward: 15.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.667 [0.000, 1.000],  loss: 3.057483, mae: 7.756915, mean_q: 14.623984, mean_eps: 0.919360\n",
            "  489/5000: episode: 21, duration: 0.333s, episode steps:  33, steps per second:  99, episode reward: 33.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.606 [0.000, 1.000],  loss: 3.258945, mae: 7.810832, mean_q: 14.653216, mean_eps: 0.915040\n",
            "  519/5000: episode: 22, duration: 0.286s, episode steps:  30, steps per second: 105, episode reward: 30.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.467 [0.000, 1.000],  loss: 2.801605, mae: 7.879074, mean_q: 14.898356, mean_eps: 0.909370\n",
            "  543/5000: episode: 23, duration: 0.167s, episode steps:  24, steps per second: 144, episode reward: 24.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 2.780991, mae: 7.890893, mean_q: 14.860711, mean_eps: 0.904510\n",
            "  566/5000: episode: 24, duration: 0.166s, episode steps:  23, steps per second: 139, episode reward: 23.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.478 [0.000, 1.000],  loss: 2.259329, mae: 7.989432, mean_q: 15.256403, mean_eps: 0.900280\n",
            "  590/5000: episode: 25, duration: 0.163s, episode steps:  24, steps per second: 147, episode reward: 24.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.417 [0.000, 1.000],  loss: 2.363046, mae: 7.985579, mean_q: 15.271338, mean_eps: 0.896050\n",
            "  620/5000: episode: 26, duration: 0.205s, episode steps:  30, steps per second: 146, episode reward: 30.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 2.633380, mae: 8.066943, mean_q: 15.407762, mean_eps: 0.891190\n",
            "  654/5000: episode: 27, duration: 0.241s, episode steps:  34, steps per second: 141, episode reward: 34.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.559 [0.000, 1.000],  loss: 3.896838, mae: 8.166362, mean_q: 15.341021, mean_eps: 0.885430\n",
            "  699/5000: episode: 28, duration: 0.327s, episode steps:  45, steps per second: 138, episode reward: 45.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.489 [0.000, 1.000],  loss: 2.776552, mae: 8.255564, mean_q: 15.811584, mean_eps: 0.878320\n",
            "  728/5000: episode: 29, duration: 0.214s, episode steps:  29, steps per second: 135, episode reward: 29.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.552 [0.000, 1.000],  loss: 3.297799, mae: 8.311754, mean_q: 15.835134, mean_eps: 0.871660\n",
            "  743/5000: episode: 30, duration: 0.105s, episode steps:  15, steps per second: 143, episode reward: 15.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.400 [0.000, 1.000],  loss: 2.401386, mae: 8.436360, mean_q: 16.388498, mean_eps: 0.867700\n",
            "  767/5000: episode: 31, duration: 0.168s, episode steps:  24, steps per second: 143, episode reward: 24.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 3.278556, mae: 8.463716, mean_q: 16.191484, mean_eps: 0.864190\n",
            "  783/5000: episode: 32, duration: 0.122s, episode steps:  16, steps per second: 132, episode reward: 16.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.438 [0.000, 1.000],  loss: 2.538038, mae: 8.431899, mean_q: 16.315359, mean_eps: 0.860590\n",
            "  811/5000: episode: 33, duration: 0.194s, episode steps:  28, steps per second: 144, episode reward: 28.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.464 [0.000, 1.000],  loss: 2.811466, mae: 8.569091, mean_q: 16.580882, mean_eps: 0.856630\n",
            "  831/5000: episode: 34, duration: 0.135s, episode steps:  20, steps per second: 148, episode reward: 20.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.400 [0.000, 1.000],  loss: 3.654310, mae: 8.553297, mean_q: 16.365751, mean_eps: 0.852310\n",
            "  843/5000: episode: 35, duration: 0.098s, episode steps:  12, steps per second: 122, episode reward: 12.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.583 [0.000, 1.000],  loss: 4.160193, mae: 8.642616, mean_q: 16.516857, mean_eps: 0.849430\n",
            "  855/5000: episode: 36, duration: 0.088s, episode steps:  12, steps per second: 136, episode reward: 12.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.333 [0.000, 1.000],  loss: 2.824133, mae: 8.612957, mean_q: 16.630514, mean_eps: 0.847270\n",
            "  869/5000: episode: 37, duration: 0.094s, episode steps:  14, steps per second: 148, episode reward: 14.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.571 [0.000, 1.000],  loss: 3.530455, mae: 8.715503, mean_q: 16.856268, mean_eps: 0.844930\n",
            "  928/5000: episode: 38, duration: 0.438s, episode steps:  59, steps per second: 135, episode reward: 59.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.424 [0.000, 1.000],  loss: 3.940904, mae: 8.789806, mean_q: 16.843642, mean_eps: 0.838360\n",
            "  967/5000: episode: 39, duration: 0.273s, episode steps:  39, steps per second: 143, episode reward: 39.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.462 [0.000, 1.000],  loss: 3.498294, mae: 8.856036, mean_q: 17.119428, mean_eps: 0.829540\n",
            "  984/5000: episode: 40, duration: 0.126s, episode steps:  17, steps per second: 134, episode reward: 17.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.647 [0.000, 1.000],  loss: 5.248067, mae: 8.944116, mean_q: 17.099535, mean_eps: 0.824500\n",
            " 1000/5000: episode: 41, duration: 0.111s, episode steps:  16, steps per second: 144, episode reward: 16.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.375 [0.000, 1.000],  loss: 3.983350, mae: 8.864412, mean_q: 16.764195, mean_eps: 0.821530\n",
            " 1028/5000: episode: 42, duration: 0.188s, episode steps:  28, steps per second: 149, episode reward: 28.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 2.921931, mae: 8.971912, mean_q: 17.400759, mean_eps: 0.817570\n",
            " 1070/5000: episode: 43, duration: 0.298s, episode steps:  42, steps per second: 141, episode reward: 42.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.476 [0.000, 1.000],  loss: 2.925506, mae: 9.117851, mean_q: 17.771135, mean_eps: 0.811270\n",
            " 1088/5000: episode: 44, duration: 0.130s, episode steps:  18, steps per second: 138, episode reward: 18.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.556 [0.000, 1.000],  loss: 3.926697, mae: 9.291181, mean_q: 18.028778, mean_eps: 0.805870\n",
            " 1111/5000: episode: 45, duration: 0.164s, episode steps:  23, steps per second: 140, episode reward: 23.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.478 [0.000, 1.000],  loss: 4.532623, mae: 9.272713, mean_q: 17.774818, mean_eps: 0.802180\n",
            " 1139/5000: episode: 46, duration: 0.180s, episode steps:  28, steps per second: 155, episode reward: 28.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.536 [0.000, 1.000],  loss: 4.018282, mae: 9.270877, mean_q: 17.895833, mean_eps: 0.797590\n",
            " 1164/5000: episode: 47, duration: 0.185s, episode steps:  25, steps per second: 135, episode reward: 25.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.600 [0.000, 1.000],  loss: 4.185866, mae: 9.400406, mean_q: 18.373386, mean_eps: 0.792820\n",
            " 1184/5000: episode: 48, duration: 0.137s, episode steps:  20, steps per second: 146, episode reward: 20.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.550 [0.000, 1.000],  loss: 3.815089, mae: 9.500785, mean_q: 18.560608, mean_eps: 0.788770\n",
            " 1204/5000: episode: 49, duration: 0.162s, episode steps:  20, steps per second: 123, episode reward: 20.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.450 [0.000, 1.000],  loss: 4.023802, mae: 9.480820, mean_q: 18.409695, mean_eps: 0.785170\n",
            " 1222/5000: episode: 50, duration: 0.153s, episode steps:  18, steps per second: 118, episode reward: 18.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.556 [0.000, 1.000],  loss: 4.416075, mae: 9.546217, mean_q: 18.493650, mean_eps: 0.781750\n",
            " 1278/5000: episode: 51, duration: 0.390s, episode steps:  56, steps per second: 143, episode reward: 56.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.554 [0.000, 1.000],  loss: 3.977235, mae: 9.709287, mean_q: 19.017588, mean_eps: 0.775090\n",
            " 1301/5000: episode: 52, duration: 0.153s, episode steps:  23, steps per second: 151, episode reward: 23.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.478 [0.000, 1.000],  loss: 5.322044, mae: 9.839118, mean_q: 19.002369, mean_eps: 0.767980\n",
            " 1317/5000: episode: 53, duration: 0.116s, episode steps:  16, steps per second: 138, episode reward: 16.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.688 [0.000, 1.000],  loss: 3.927511, mae: 9.788312, mean_q: 19.087645, mean_eps: 0.764470\n",
            " 1393/5000: episode: 54, duration: 0.504s, episode steps:  76, steps per second: 151, episode reward: 76.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.461 [0.000, 1.000],  loss: 3.855681, mae: 10.021038, mean_q: 19.736191, mean_eps: 0.756190\n",
            " 1408/5000: episode: 55, duration: 0.101s, episode steps:  15, steps per second: 148, episode reward: 15.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.533 [0.000, 1.000],  loss: 4.269795, mae: 10.073568, mean_q: 19.762176, mean_eps: 0.748000\n",
            " 1440/5000: episode: 56, duration: 0.211s, episode steps:  32, steps per second: 151, episode reward: 32.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.531 [0.000, 1.000],  loss: 4.509156, mae: 10.262887, mean_q: 20.270239, mean_eps: 0.743770\n",
            " 1500/5000: episode: 57, duration: 0.394s, episode steps:  60, steps per second: 152, episode reward: 60.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.483 [0.000, 1.000],  loss: 5.581698, mae: 10.379912, mean_q: 20.217537, mean_eps: 0.735490\n",
            " 1549/5000: episode: 58, duration: 0.350s, episode steps:  49, steps per second: 140, episode reward: 49.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.469 [0.000, 1.000],  loss: 3.132722, mae: 10.514624, mean_q: 20.823757, mean_eps: 0.725680\n",
            " 1663/5000: episode: 59, duration: 0.757s, episode steps: 114, steps per second: 151, episode reward: 114.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.535 [0.000, 1.000],  loss: 3.729040, mae: 10.874199, mean_q: 21.629070, mean_eps: 0.711010\n",
            " 1697/5000: episode: 60, duration: 0.238s, episode steps:  34, steps per second: 143, episode reward: 34.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.529 [0.000, 1.000],  loss: 4.733762, mae: 11.148207, mean_q: 22.049282, mean_eps: 0.697690\n",
            " 1752/5000: episode: 61, duration: 0.377s, episode steps:  55, steps per second: 146, episode reward: 55.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.527 [0.000, 1.000],  loss: 3.672300, mae: 11.319605, mean_q: 22.609088, mean_eps: 0.689680\n",
            " 1811/5000: episode: 62, duration: 0.395s, episode steps:  59, steps per second: 149, episode reward: 59.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.458 [0.000, 1.000],  loss: 4.681770, mae: 11.525726, mean_q: 22.819584, mean_eps: 0.679420\n",
            " 1856/5000: episode: 63, duration: 0.318s, episode steps:  45, steps per second: 141, episode reward: 45.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.511 [0.000, 1.000],  loss: 5.832302, mae: 11.788347, mean_q: 23.251140, mean_eps: 0.670060\n",
            " 1932/5000: episode: 64, duration: 0.550s, episode steps:  76, steps per second: 138, episode reward: 76.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.487 [0.000, 1.000],  loss: 4.360513, mae: 11.871100, mean_q: 23.626411, mean_eps: 0.659170\n",
            " 1971/5000: episode: 65, duration: 0.413s, episode steps:  39, steps per second:  94, episode reward: 39.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.462 [0.000, 1.000],  loss: 4.877911, mae: 12.079899, mean_q: 24.076975, mean_eps: 0.648820\n",
            " 1996/5000: episode: 66, duration: 0.255s, episode steps:  25, steps per second:  98, episode reward: 25.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.440 [0.000, 1.000],  loss: 4.526495, mae: 12.141723, mean_q: 24.109263, mean_eps: 0.643060\n",
            " 2017/5000: episode: 67, duration: 0.210s, episode steps:  21, steps per second: 100, episode reward: 21.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.619 [0.000, 1.000],  loss: 5.826690, mae: 12.247138, mean_q: 24.124509, mean_eps: 0.638920\n",
            " 2096/5000: episode: 68, duration: 0.767s, episode steps:  79, steps per second: 103, episode reward: 79.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.506 [0.000, 1.000],  loss: 3.793240, mae: 12.514908, mean_q: 25.070427, mean_eps: 0.629920\n",
            " 2165/5000: episode: 69, duration: 0.979s, episode steps:  69, steps per second:  70, episode reward: 69.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.493 [0.000, 1.000],  loss: 4.105018, mae: 12.768217, mean_q: 25.582914, mean_eps: 0.616600\n",
            " 2240/5000: episode: 70, duration: 0.515s, episode steps:  75, steps per second: 146, episode reward: 75.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.520 [0.000, 1.000],  loss: 4.538150, mae: 13.022334, mean_q: 26.113723, mean_eps: 0.603640\n",
            " 2321/5000: episode: 71, duration: 0.552s, episode steps:  81, steps per second: 147, episode reward: 81.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.481 [0.000, 1.000],  loss: 4.987109, mae: 13.330904, mean_q: 26.715343, mean_eps: 0.589600\n",
            " 2355/5000: episode: 72, duration: 0.233s, episode steps:  34, steps per second: 146, episode reward: 34.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.471 [0.000, 1.000],  loss: 5.024401, mae: 13.659659, mean_q: 27.262073, mean_eps: 0.579250\n",
            " 2424/5000: episode: 73, duration: 0.477s, episode steps:  69, steps per second: 145, episode reward: 69.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.507 [0.000, 1.000],  loss: 5.416815, mae: 13.688877, mean_q: 27.316048, mean_eps: 0.569980\n",
            " 2470/5000: episode: 74, duration: 0.346s, episode steps:  46, steps per second: 133, episode reward: 46.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.522 [0.000, 1.000],  loss: 5.286473, mae: 13.910553, mean_q: 27.824872, mean_eps: 0.559630\n",
            " 2487/5000: episode: 75, duration: 0.151s, episode steps:  17, steps per second: 112, episode reward: 17.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.588 [0.000, 1.000],  loss: 7.020080, mae: 13.991868, mean_q: 28.007907, mean_eps: 0.553960\n",
            " 2603/5000: episode: 76, duration: 0.820s, episode steps: 116, steps per second: 141, episode reward: 116.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.543 [0.000, 1.000],  loss: 5.857860, mae: 14.172178, mean_q: 28.362771, mean_eps: 0.541990\n",
            " 2626/5000: episode: 77, duration: 0.171s, episode steps:  23, steps per second: 134, episode reward: 23.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.435 [0.000, 1.000],  loss: 3.680307, mae: 14.555655, mean_q: 29.277511, mean_eps: 0.529480\n",
            " 2697/5000: episode: 78, duration: 0.476s, episode steps:  71, steps per second: 149, episode reward: 71.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.465 [0.000, 1.000],  loss: 5.077192, mae: 14.605070, mean_q: 29.371090, mean_eps: 0.521020\n",
            " 2782/5000: episode: 79, duration: 0.596s, episode steps:  85, steps per second: 143, episode reward: 85.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.494 [0.000, 1.000],  loss: 5.397901, mae: 14.847429, mean_q: 29.803463, mean_eps: 0.506980\n",
            " 2840/5000: episode: 80, duration: 0.386s, episode steps:  58, steps per second: 150, episode reward: 58.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.517 [0.000, 1.000],  loss: 4.151335, mae: 15.124787, mean_q: 30.663144, mean_eps: 0.494110\n",
            " 2915/5000: episode: 81, duration: 0.526s, episode steps:  75, steps per second: 142, episode reward: 75.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.467 [0.000, 1.000],  loss: 5.541218, mae: 15.378236, mean_q: 31.056412, mean_eps: 0.482140\n",
            " 2997/5000: episode: 82, duration: 0.546s, episode steps:  82, steps per second: 150, episode reward: 82.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.451 [0.000, 1.000],  loss: 5.244655, mae: 15.586551, mean_q: 31.568414, mean_eps: 0.468010\n",
            " 3088/5000: episode: 83, duration: 0.633s, episode steps:  91, steps per second: 144, episode reward: 91.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.538 [0.000, 1.000],  loss: 5.898688, mae: 15.965303, mean_q: 32.241092, mean_eps: 0.452440\n",
            " 3182/5000: episode: 84, duration: 0.650s, episode steps:  94, steps per second: 145, episode reward: 94.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.564 [0.000, 1.000],  loss: 5.139606, mae: 16.253758, mean_q: 32.912323, mean_eps: 0.435790\n",
            " 3283/5000: episode: 85, duration: 0.692s, episode steps: 101, steps per second: 146, episode reward: 101.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.515 [0.000, 1.000],  loss: 5.039050, mae: 16.568538, mean_q: 33.721701, mean_eps: 0.418240\n",
            " 3414/5000: episode: 86, duration: 1.062s, episode steps: 131, steps per second: 123, episode reward: 131.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.527 [0.000, 1.000],  loss: 5.701921, mae: 17.107276, mean_q: 34.611867, mean_eps: 0.397360\n",
            " 3560/5000: episode: 87, duration: 1.266s, episode steps: 146, steps per second: 115, episode reward: 146.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.521 [0.000, 1.000],  loss: 5.867044, mae: 17.695767, mean_q: 35.769283, mean_eps: 0.372430\n",
            " 3760/5000: episode: 88, duration: 1.969s, episode steps: 200, steps per second: 102, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.525 [0.000, 1.000],  loss: 5.095627, mae: 18.352087, mean_q: 37.251680, mean_eps: 0.341290\n",
            " 3916/5000: episode: 89, duration: 1.215s, episode steps: 156, steps per second: 128, episode reward: 156.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.487 [0.000, 1.000],  loss: 5.700543, mae: 18.967570, mean_q: 38.510666, mean_eps: 0.309250\n",
            " 4109/5000: episode: 90, duration: 1.325s, episode steps: 193, steps per second: 146, episode reward: 193.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.534 [0.000, 1.000],  loss: 5.576251, mae: 19.667126, mean_q: 40.008144, mean_eps: 0.277840\n",
            " 4309/5000: episode: 91, duration: 1.319s, episode steps: 200, steps per second: 152, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.520 [0.000, 1.000],  loss: 5.869479, mae: 20.552729, mean_q: 41.846954, mean_eps: 0.242470\n",
            " 4494/5000: episode: 92, duration: 1.287s, episode steps: 185, steps per second: 144, episode reward: 185.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.530 [0.000, 1.000],  loss: 5.460731, mae: 21.350096, mean_q: 43.441493, mean_eps: 0.207820\n",
            " 4694/5000: episode: 93, duration: 1.343s, episode steps: 200, steps per second: 149, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.515 [0.000, 1.000],  loss: 5.307369, mae: 22.080310, mean_q: 45.006795, mean_eps: 0.173170\n",
            " 4894/5000: episode: 94, duration: 1.361s, episode steps: 200, steps per second: 147, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.515 [0.000, 1.000],  loss: 5.345593, mae: 22.918734, mean_q: 46.693623, mean_eps: 0.137170\n",
            "done, took 37.838 seconds\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dqn.test(env, nb_episodes=20, visualize=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bkKOscyvlbDf",
        "outputId": "56ebf85d-64e6-423a-e656-c991db6a6519"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing for 20 episodes ...\n",
            "Episode 1: reward: 200.000, steps: 200\n",
            "Episode 2: reward: 200.000, steps: 200\n",
            "Episode 3: reward: 200.000, steps: 200\n",
            "Episode 4: reward: 193.000, steps: 193\n",
            "Episode 5: reward: 200.000, steps: 200\n",
            "Episode 6: reward: 200.000, steps: 200\n",
            "Episode 7: reward: 200.000, steps: 200\n",
            "Episode 8: reward: 168.000, steps: 168\n",
            "Episode 9: reward: 200.000, steps: 200\n",
            "Episode 10: reward: 200.000, steps: 200\n",
            "Episode 11: reward: 193.000, steps: 193\n",
            "Episode 12: reward: 200.000, steps: 200\n",
            "Episode 13: reward: 200.000, steps: 200\n",
            "Episode 14: reward: 200.000, steps: 200\n",
            "Episode 15: reward: 183.000, steps: 183\n",
            "Episode 16: reward: 200.000, steps: 200\n",
            "Episode 17: reward: 188.000, steps: 188\n",
            "Episode 18: reward: 200.000, steps: 200\n",
            "Episode 19: reward: 194.000, steps: 194\n",
            "Episode 20: reward: 200.000, steps: 200\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f9dad599d60>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    }
  ]
}